import os
import streamlit as st
import datetime

# –í–ê–ñ–ù–û: –≠—Ç–∞ —Å—Ç—Ä–æ–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–µ—Ä–≤–æ–π –∫–æ–º–∞–Ω–¥–æ–π Streamlit
st.set_page_config(page_title="–ü–æ–∏—Å–∫ —Å–ø–æ—Ä–Ω—ã—Ö –Ω–∞–ª–æ–≥–æ–≤—ã—Ö —Å–∏—Ç—É–∞—Ü–∏–π", layout="wide")

from dotenv import load_dotenv
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_qdrant import QdrantVectorStore
from langchain_openai import ChatOpenAI
import qdrant_client
import re

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv(dotenv_path=".env")
PROVIDER_API_KEY = os.getenv("PROVIDER_API_KEY")
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
COLLECTION_NAME = "enciclop"  # –ò–º—è –≤–∞—à–µ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ Qdrant

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
@st.cache_resource
def get_embeddings():
    return HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

embeddings = get_embeddings()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Qdrant
@st.cache_resource
def get_qdrant_client():
    client = qdrant_client.QdrantClient(
        url=QDRANT_URL,
        api_key=QDRANT_API_KEY,
        prefer_grpc=False
    )
    return client

qdrant_client = get_qdrant_client()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
@st.cache_resource
def get_vector_store():
    return QdrantVectorStore(
        client=qdrant_client,
        collection_name=COLLECTION_NAME,
        embedding=embeddings,
    )

vector_store = get_vector_store()

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
def extract_structured_info(page_content_text, metadata):
    source = metadata.get("source", "–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ —É–∫–∞–∑–∞–Ω")
    section = "–†–∞–∑–¥–µ–ª –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
    point = "–ü—É–Ω–∫—Ç –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
    title = page_content_text 

    pattern = re.compile(
        r"–†–∞–∑–¥–µ–ª:\s*(?P<section>.*?)\s*"
        r"–ü—É–Ω–∫—Ç –æ–≥–ª–∞–≤–ª–µ–Ω–∏—è:\s*(?P<point_num>\d[\d\.]*[\d])\s*\.?"
        r"\s*(?P<title>.*)",
        re.IGNORECASE | re.DOTALL
    )
    match = pattern.search(page_content_text)

    if match:
        section_candidate = match.group("section").strip()
        point_candidate = match.group("point_num").strip()
        title_candidate = match.group("title").strip()

        if section_candidate:
            section = section_candidate
        if point_candidate:
            point = point_candidate
        
        if title_candidate:
            title = title_candidate
        elif point_candidate:
            title = f"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—É–Ω–∫—Ç–∞ {point_candidate} –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω–æ (–∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: '{page_content_text[:50]}...')."
            
    else:
        fallback_pattern = re.compile(
            r"–ü—É–Ω–∫—Ç –æ–≥–ª–∞–≤–ª–µ–Ω–∏—è:\s*(?P<point_num>\d[\d\.]*[\d])\s*\.?"
            r"\s*(?P<title>.*)",
            re.IGNORECASE | re.DOTALL
        )
        fallback_match = fallback_pattern.search(page_content_text)
        if fallback_match:
            point_candidate = fallback_match.group("point_num").strip()
            title_candidate = fallback_match.group("title").strip()

            if point_candidate:
                point = point_candidate
            if title_candidate:
                title = title_candidate
            elif point_candidate:
                 title = f"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—É–Ω–∫—Ç–∞ {point_candidate} –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω–æ (–∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: '{page_content_text[:50]}...')."
        # –ï—Å–ª–∏ –∏ –æ—Å–Ω–æ–≤–Ω–æ–π –∏ fallback –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, title –æ—Å—Ç–∞–Ω–µ—Ç—Å—è page_content_text

    return {
        "section": section,
        "point": point,
        "title": title,
        "source": source,
        "score": 0, # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º, –±—É–¥–µ—Ç –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω–æ –≤ find_relevant_situations
        "full_content": page_content_text
    }

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏–π
def find_relevant_situations(query, top_k=5):
    docs_with_scores = vector_store.similarity_search_with_score(query, k=top_k)
    
    results = []
    for doc, score in docs_with_scores:
        info = extract_structured_info(doc.page_content, doc.metadata)
        info["score"] = score
        results.append(info)
    
    return results

# --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit ---
st.title("üîç –ü–æ–∏—Å–∫ —Å–ø–æ—Ä–Ω—ã—Ö –Ω–∞–ª–æ–≥–æ–≤—ã—Ö —Å–∏—Ç—É–∞—Ü–∏–π")
st.write("–û–ø–∏—à–∏—Ç–µ –≤–∞—à—É —Å–∏—Ç—É–∞—Ü–∏—é, –∏ —Å–∏—Å—Ç–µ–º–∞ –Ω–∞–π–¥–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –ø—É–Ω–∫—Ç–æ–≤ —Å–ø–æ—Ä–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏–π.")

query = st.text_area("–û–ø–∏—à–∏—Ç–µ –≤–∞—à—É —Å–∏—Ç—É–∞—Ü–∏—é:", 
                     placeholder="–ü—Ä–∏–º–µ—Ä: –ú–æ–∂–Ω–æ –ª–∏ —É—á–µ—Å—Ç—å —Ä–∞—Å—Ö–æ–¥—ã –Ω–∞ —Ç–∞–∫—Å–∏ –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –≤ –∫–æ–º–∞–Ω–¥–∏—Ä–æ–≤–∫–µ...",
                     height=150)

if "current_date" not in st.session_state:
    st.session_state.current_date = datetime.date.today().strftime("%d.%m.%Y")

if st.button("–ù–∞–π—Ç–∏ —Å–∏—Ç—É–∞—Ü–∏–∏"):
    if not query:
        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –≤–∞—à—É —Å–∏—Ç—É–∞—Ü–∏—é")
    else:
        with st.spinner("–ò–¥–µ—Ç –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π..."):
            situations = find_relevant_situations(query, top_k=5)
            
            if not situations:
                st.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π –ø—É–Ω–∫—Ç–æ–≤ –¥–ª—è –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å.")
            else:
                st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(situations)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π –ø—É–Ω–∫—Ç–æ–≤:")
                
                for i, sit in enumerate(situations, 1):
                    # –û—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—É–Ω–∫—Ç–∞
                    st.markdown(f"**{i}. {sit['title']}**")
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: –†–∞–∑–¥–µ–ª, –ü—É–Ω–∫—Ç, –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º HTML –¥–ª—è –±–æ–ª–µ–µ —Ç–æ–Ω–∫–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –Ω–∞–¥ —Å—Ç–∏–ª–µ–º –∏ –æ—Ç—Å—Ç—É–ø–∞–º–∏
                    details_html = f"""
                    <div style="margin-left: 20px; font-size: 0.9em; color: #4F4F4F;">
                        <i>
                            –†–∞–∑–¥–µ–ª: {sit['section']} ‚Ä¢ 
                            –ü—É–Ω–∫—Ç: {sit['point']} ‚Ä¢ 
                            –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {sit['score']:.2f}
                        </i>
                    </div>
                    """
                    st.markdown(details_html, unsafe_allow_html=True)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
                    if i < len(situations):
                        st.divider()
                    else:
                        st.markdown("<br>", unsafe_allow_html=True) # –ù–µ–±–æ–ª—å—à–æ–π –æ—Ç—Å—Ç—É–ø –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞

# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ
st.sidebar.title("–û —Å–∏—Å—Ç–µ–º–µ")
st.sidebar.info(
    """
   testing
    """
)
st.sidebar.divider()
st.sidebar.markdown(f"""
<div style='font-size: 0.875em; color: gray;'>
    ¬© Prozorovskiy Dmitriy.
    –î–∞—Ç–∞: {st.session_state.current_date}
</div>
""", 
unsafe_allow_html=True)
