import os
import streamlit as st
import datetime

st.set_page_config(page_title="–ü–æ–∏—Å–∫ –≤ –æ–≥–ª–∞–≤–ª–µ–Ω–∏–∏", layout="wide")

from dotenv import load_dotenv
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_qdrant import QdrantVectorStore
import qdrant_client
import re
from sentence_transformers import CrossEncoder

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv(dotenv_path=".env")
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
COLLECTION_NAME = "enciclop"


@st.cache_resource
def get_embeddings():
    return HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

# 1. –°–û–ó–î–ê–ï–ú –≠–ö–ó–ï–ú–ü–õ–Ø–† –ú–û–î–ï–õ–ò –≠–ú–ë–ï–î–î–ò–ù–ì–û–í
embeddings_instance = get_embeddings()

@st.cache_resource
def get_qdrant_client():
    return qdrant_client.QdrantClient(
        url=QDRANT_URL, api_key=QDRANT_API_KEY, prefer_grpc=False
    )

# 2. –°–û–ó–î–ê–ï–ú –≠–ö–ó–ï–ú–ü–õ–Ø–† –ö–õ–ò–ï–ù–¢–ê QDRANT
qdrant_client_instance = get_qdrant_client()

@st.cache_resource
def get_vector_store():
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ–ø–µ—Ä—å –±—É–¥–µ—Ç –≤–∏–¥–µ—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—É—é —Ä–∞–Ω–µ–µ embeddings_instance
    return QdrantVectorStore(
        client=qdrant_client_instance,
        collection_name=COLLECTION_NAME,
        embedding=embeddings_instance, # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—É—é embeddings_instance
    )

# 3. –°–û–ó–î–ê–ï–ú –≠–ö–ó–ï–ú–ü–õ–Ø–† –í–ï–ö–¢–û–†–ù–û–ì–û –•–†–ê–ù–ò–õ–ò–©–ê
vector_store = get_vector_store()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Cross-Encoder –¥–ª—è –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
@st.cache_resource
def get_reranker():
    model_name = 'cross-encoder/mmarco-mMiniLMv2-L12-H384-v1'
    try:
        model = CrossEncoder(model_name, device='cpu')
        return model
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å reranker: {e}")
        return None

reranker = get_reranker()

# ... (–æ—Å—Ç–∞–ª—å–Ω–∞—è —á–∞—Å—Ç—å –≤–∞—à–µ–≥–æ –∫–æ–¥–∞: extract_structured_info, find_relevant_situations, –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit) ...
def extract_structured_info(page_content_text, metadata):
    source = metadata.get("source", "–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ —É–∫–∞–∑–∞–Ω")
    section = "–†–∞–∑–¥–µ–ª –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
    point = "–ü—É–Ω–∫—Ç –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
    title = page_content_text 

    pattern = re.compile(
        r"–†–∞–∑–¥–µ–ª:\s*(?P<section>.*?)\s*"
        r"–ü—É–Ω–∫—Ç –æ–≥–ª–∞–≤–ª–µ–Ω–∏—è:\s*(?P<point_num>\d[\d\.]*[\d])\s*\.?"
        r"\s*(?P<title>.*)",
        re.IGNORECASE | re.DOTALL
    )
    match = pattern.search(page_content_text)

    if match:
        section_candidate = match.group("section").strip()
        point_candidate = match.group("point_num").strip()
        title_candidate = match.group("title").strip()

        if section_candidate: section = section_candidate
        if point_candidate: point = point_candidate
        
        if title_candidate:
            title = title_candidate
        elif point_candidate:
            title = f"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—É–Ω–∫—Ç–∞ {point_candidate} –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω–æ."
    else:
        fallback_pattern = re.compile(
            r"–ü—É–Ω–∫—Ç –æ–≥–ª–∞–≤–ª–µ–Ω–∏—è:\s*(?P<point_num>\d[\d\.]*[\d])\s*\.?"
            r"\s*(?P<title>.*)", re.IGNORECASE | re.DOTALL
        )
        fallback_match = fallback_pattern.search(page_content_text)
        if fallback_match:
            point_candidate = fallback_match.group("point_num").strip()
            title_candidate = fallback_match.group("title").strip()
            if point_candidate: point = point_candidate
            if title_candidate:
                title = title_candidate
            elif point_candidate:
                 title = f"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—É–Ω–∫—Ç–∞ {point_candidate} –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω–æ."
    return {
        "section": section, "point": point, "title": title, "source": source,
        "score": 0, "full_content": page_content_text
    }

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏–π —Å –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º
def find_relevant_situations(query, initial_top_k=20, final_top_k=7):
    docs_with_scores_qdrant = vector_store.similarity_search_with_score(query, k=initial_top_k)
    
    if not docs_with_scores_qdrant:
        return []

    if reranker is None:
        st.warning("–ú–æ–¥–µ–ª—å –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–º–∏.")
        results_no_rerank = []
        for doc, score in docs_with_scores_qdrant[:final_top_k]:
            info = extract_structured_info(doc.page_content, doc.metadata)
            info["score"] = score 
            results_no_rerank.append(info)
        return results_no_rerank

    sentence_pairs = []
    candidate_docs_map = {} 
    for idx, (doc, qdrant_score) in enumerate(docs_with_scores_qdrant):
        sentence_pairs.append([query, doc.page_content])
        candidate_docs_map[idx] = (doc, qdrant_score)

    try:
        reranker_scores = reranker.predict(sentence_pairs, convert_to_tensor=True)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        results_fallback = []
        for doc, score in docs_with_scores_qdrant[:final_top_k]:
            info = extract_structured_info(doc.page_content, doc.metadata)
            info["score"] = score 
            results_fallback.append(info)
        return results_fallback

    reranked_docs_with_new_scores = []
    for i in range(len(sentence_pairs)):
        original_doc, original_qdrant_score = candidate_docs_map[i]
        info = extract_structured_info(original_doc.page_content, original_doc.metadata)
        info["score"] = reranker_scores[i].item() 
        reranked_docs_with_new_scores.append(info)
        
    reranked_docs_with_new_scores.sort(key=lambda x: x["score"], reverse=True)
    
    return reranked_docs_with_new_scores[:final_top_k]


# --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit ---
st.title("üîç –ü–æ–∏—Å–∫ –≤ –æ–≥–ª–∞–≤–ª–µ–Ω–∏–∏")
st.write("–û–ø–∏—à–∏—Ç–µ –≤–∞—à—É —Å–∏—Ç—É–∞—Ü–∏—é, –∏ —Å–∏—Å—Ç–µ–º–∞ –Ω–∞–π–¥–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –ø—É–Ω–∫—Ç–æ–≤ —Å–ø–æ—Ä–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏–π.")

query = st.text_area("–û–ø–∏—à–∏—Ç–µ –≤–∞—à—É —Å–∏—Ç—É–∞—Ü–∏—é:", 
                     placeholder="–ü—Ä–∏–º–µ—Ä: –Ω—É–∂–Ω–æ –ª–∏ –∫–∞–∂–¥—ã–π –º–µ—Å—è—Ü —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å –∞–∫—Ç—ã –æ–∫–∞–∑–∞–Ω–Ω—ã—Ö —É—Å–ª—É–≥ –≤ —Ä–∞–º–∫–∞—Ö –¥–æ–≥–æ–≤–æ—Ä–∞ –∞—Ä–µ–Ω–¥—ã",
                     height=150)

if "current_date" not in st.session_state:
    st.session_state.current_date = datetime.date.today().strftime("%d.%m.%Y")

if st.button("–ù–∞–π—Ç–∏ —Å–∏—Ç—É–∞—Ü–∏–∏"):
    if not query:
        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–ø–∏—à–∏—Ç–µ –≤–∞—à—É —Å–∏—Ç—É–∞—Ü–∏—é")
    else:
        with st.spinner("–ò–¥–µ—Ç –ø–æ–∏—Å–∫ –∏ –∞–Ω–∞–ª–∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π..."):
            situations = find_relevant_situations(query, initial_top_k=25, final_top_k=7) 
            
            if not situations:
                st.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π –ø—É–Ω–∫—Ç–æ–≤ –¥–ª—è –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å.")
            else:
                st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(situations)} –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π –ø—É–Ω–∫—Ç–æ–≤:")
                
                for i, sit in enumerate(situations, 1):
                    st.markdown(f"**{i}. {sit['title']}**")
                    details_html = f"""
                    <div style="margin-left: 20px; font-size: 0.9em; color: #4F4F4F;">
                        <i>
                            –†–∞–∑–¥–µ–ª: {sit['section']} ‚Ä¢ 
                            –ü—É–Ω–∫—Ç: {sit['point']} ‚Ä¢ 
                            –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {sit['score']:.2f} 
                        </i>
                    </div>
                    """
                    st.markdown(details_html, unsafe_allow_html=True)
                    if i < len(situations):
                        st.divider()
                    else:
                        st.markdown("<br>", unsafe_allow_html=True)

# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ
st.sidebar.title("–û —Å–∏—Å—Ç–µ–º–µ")
st.sidebar.info(
    """
    RAG + —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –∏ –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ.
    """
)
st.sidebar.divider()
st.sidebar.markdown(f"""
<div style='font-size: 0.875em; color: gray;'>
    ¬© Prozorovskiy Dmitriy.
    –î–∞—Ç–∞: 01.03.2025
</div>
""", 
unsafe_allow_html=True)
